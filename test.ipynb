{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "proud-thanksgiving",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.utils.data as Data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import jieba\n",
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "removed-shakespeare",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "w2v_model=KeyedVectors.load_word2vec_format(\"/Users/jasondennis/Desktop/graduate-design/CNN/test1/sgns.zhihu.bigram.bz2\",binary=False)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "commercial-metabolism",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.cat((torch.from_numpy(w2v_model['棒'].reshape((1,300))),torch.from_numpy(w2v_model['好'].reshape((1,300))),torch.from_numpy(w2v_model['牛'].reshape((1,300)))),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "occupational-attention",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 300])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "activated-contributor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def build_sentence_vec(sentence_word,asize,bsize,w2v_model):\n",
    "    x=torch.zeros(1,bsize)\n",
    "    y=torch.zeros(1,bsize)\n",
    "    gap=sentence_word\n",
    "    if asize<=len(sentence_word):\n",
    "        for j in range(asize):\n",
    "            try:\n",
    "                x=torch.cat((x,torch.from_numpy(w2v_model[gap[j]].reshape((1,size)))),0)\n",
    "            except KeyError:\n",
    "                x=torch.cat((x,y),0)\n",
    "            \n",
    "    else:\n",
    "        for j in range(len(sentence_word)):\n",
    "            try:\n",
    "                x=torch.cat((x,torch.from_numpy(w2v_model[gap[j]].reshape((1,size)))),0)\n",
    "            except KeyError:\n",
    "                x=torch.cat((x,y),0)\n",
    "        for j in range(asize,len(sentence_word),1):\n",
    "            x=torch.cat((x,y),0)\n",
    "    return x\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caroline-boating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading all-in-one\n",
      "ok\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print('loading all-in-one')\n",
    "all_in_one=pd.read_csv('/Users/jasondennis/Desktop/graduate-design/data/all-in-one.csv')\n",
    "sentence=list(all_in_one['Comment'])\n",
    "print('ok')\n",
    "import jieba.posseg as pseg\n",
    "\n",
    "sentence_word=[ ]\n",
    "for i in range(len(sentence)):\n",
    "    listp=[ ]\n",
    "    tag_filter = ['n', 'v','s','a','z','y']  # 需要保留的词性\n",
    "    seg_result = pseg.cut(sentence[i])  # 结果是一个pair，有flag和word两种值\n",
    "    listp.append(s.word for s in seg_result if s.flag in tag_filter)\n",
    "    sentence_word.append(listp)\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "complex-korean",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/y_/v6f38kjs6tncrsfkklcmjf640000gn/T/jieba.cache\n",
      "Loading model cost 0.775 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 300])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z=build_sentence_vec(sentence_word[0],36,300,w2v_model)\n",
    "z.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "judicial-specification",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "#     x=torch.zeros(1,300)\n",
    "#     y=torch.zeros(1,300)\n",
    "#     gap=sentence_word[0]\n",
    "#     if 36<=len(gap):\n",
    "#         for j in range(36):\n",
    "#             try:\n",
    "#                 x=torch.cat((x,torch.from_numpy(w2v_model[gap[j]].reshape((1,300)))),0)\n",
    "#             except KeyError:\n",
    "#                 x=torch.cat((x,y),0)\n",
    "            \n",
    "#     else:\n",
    "#         for j in range(len(gap)):\n",
    "#             try:\n",
    "#                 x=torch.cat((x,torch.from_numpy(w2v_model[gap[j]].reshape((1,300)))),0)\n",
    "#             except KeyError:\n",
    "#                 x=torch.cat((x,y),0)\n",
    "#         for j in range(36,len(gap),1):\n",
    "#             x=torch.cat((x,y),0)\n",
    "#     print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
