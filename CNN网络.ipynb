{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "turkish-brooks",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import jieba.posseg as pseg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.utils.data as Data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import jieba\n",
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "spare-matrix",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            # 卷积参数设置\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,  # 输入数据的通道为1，即卷积核通道数为1\n",
    "                out_channels=16,  # 输出通道数为16，即卷积核个数为16\n",
    "                kernel_size=(2,300),  # 卷积核的尺寸为 5*5\n",
    "                stride=1,  # 卷积核的滑动步长为1\n",
    "                padding=2,  # 边缘零填充为2\n",
    "            ),\n",
    "            nn.ReLU(),  # 激活函数为Relu\n",
    "            nn.MaxPool2d(2),  # 最大池化 2*2\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, (3,300), 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        # 全连接层\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(32 * 7 * 7, 120),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(120, 36),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc3 = nn.Linear(36, 10)  # 最后输出结果个数为2\n",
    "        self.soft = nn.Softmax()\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        in_size = x.size(0)\n",
    "        out = self.relu(self.mp(self.conv1(x)))\n",
    "        out = self.relu(self.mp(self.conv2(out)))\n",
    "        out = out.view(in_size, -1)\n",
    "        out = self.relu(self.fc1(out))\n",
    "        out = self.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return self.soft(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "boring-machine",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "deadly-surface",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading all-in-one\n",
      "load positive\n",
      "load negative\n"
     ]
    }
   ],
   "source": [
    "print('loading all-in-one')\n",
    "all_in_one=pd.read_csv('/Users/jasondennis/Desktop/graduate-design/data/all-in-one.csv')\n",
    "print('load positive')\n",
    "pos=pd.read_csv('/Users/jasondennis/Desktop/graduate-design/data/positive.csv')\n",
    "print('load negative')\n",
    "neg=pd.read_csv('/Users/jasondennis/Desktop/graduate-design/data/negative.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "understanding-philip",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Comment  posneg\n",
      "0        机甲之战超超好看，比变形金刚强；人，神，变异人，人工智能互殴，强强强强；每一小段末句都是槽...       1\n",
      "1        说实话其实剧情就那样吧，非漫威粉看着可能有的地方会get不到G点吧。（其实漫威卖的不是剧情...       1\n",
      "2                                     没有了洛基这个小基仔真是觉得即墨如雪啊       1\n",
      "3        看毕，我激动地对友人说，等等奥创要来毁灭台北怎么办厚，她拍了拍我肩膀，没事，反正你买了两份...       1\n",
      "4                                     哪个保证一刀不剪的，不是剪了好几刀吗！       1\n",
      "...                                                   ...     ...\n",
      "739275                   电影很一般，远不如冰河世纪这些，正常打7分，打1分是因为水军太多       0\n",
      "739276   作为喜剧笑点太生硬而且低龄化，情节走向俗套，感觉不如迪士尼的任何一部动画电影，在我心中和喜...       0\n",
      "739277                  为什么每次这种莫名其妙的动画片分数这么高，豆瓣这群装逼犯又发作了吗       0\n",
      "739278                                                 无感       0\n",
      "739279                                          我来拉分，睡着了都       0\n",
      "\n",
      "[739280 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(all_in_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "extra-liberal",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence=list(all_in_one['Comment'])\n",
    "seg=list(all_in_one['posneg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "stuffed-adelaide",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence_jieba=[ ]\n",
    "# for x in range(len(all_in_one)):\n",
    "#     sentence_jieba.append(build_sentence_vec(all_in_one['Comment'][x],300,w2v_model))\n",
    "#     score.append(all_in_one['posneg'][x])\n",
    "# print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "charming-aerospace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import jieba.posseg as pseg\n",
    "\n",
    "sentence_word=[ ]\n",
    "for i in range(len(sentence)):\n",
    "\n",
    "    list=[ ]\n",
    "    tag_filter = ['n', 'v','s','a','z','y']  # 需要保留的词性\n",
    "    seg_result = pseg.cut(sentence[i])  # 结果是一个pair，有flag和word两种值\n",
    "    list.append(s.word for s in seg_result if s.flag in tag_filter)\n",
    "    sentence_word.append(list)\n",
    "    \n",
    "    \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acute-attempt",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/y_/v6f38kjs6tncrsfkklcmjf640000gn/T/jieba.cache\n",
      "Loading model cost 0.744 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "词性过滤完成\n",
      "[['剧情 吧 看着 可能 有 地方 会 不到 吧 剧情 人物 呀 宇宙 棒棒 漫威粉 全程 高能 燃爆 大法 好']]\n"
     ]
    }
   ],
   "source": [
    "# import jieba.posseg as pseg\n",
    "# list = []\n",
    "# tag_filter = ['n', 'v','s','a','z','y']  # 需要保留的词性\n",
    "# seg_result = pseg.cut(sentence[1])  # 结果是一个pair，有flag和word两种值\n",
    "# list.append([\" \".join(s.word for s in seg_result if s.flag in tag_filter)])\n",
    "# print(\"词性过滤完成\")\n",
    "# print(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "trying-advantage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "w2v_model=KeyedVectors.load_word2vec_format(\"/Users/jasondennis/Desktop/graduate-design/CNN/test1/sgns.zhihu.bigram.bz2\",binary=False)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "focused-american",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def build_sentence_vec(sentence_word,asize,bsize,w2v_model):\n",
    "    x=torch.empty(1,bsize)\n",
    "    y=torch.zeros(1,bsize)\n",
    "#     for i in range(len(sentence_word)):\n",
    "#         gap=sentence_word[i]\n",
    "        if asize<=len(sentence_word):\n",
    "            for j in range(asize):\n",
    "                x=torch.cat((x,torch.from_numpy(w2v_model[gap[j]].reshape((1,size)))),0)\n",
    "        else:\n",
    "            for j in range(len(sentence_word)):\n",
    "                x=torch.cat((x,torch.from_numpy(w2v_model[gap[j]].reshape((1,size)))),0)\n",
    "            for j in range(asize,len(sentence_word),1):\n",
    "                x=torch.cat((x,y),0)\n",
    "    return x\n",
    "\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "superb-tonight",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-191fde242623>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuild_sentence_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m36\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw2v_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-bb457ab7ac17>\u001b[0m in \u001b[0;36mbuild_sentence_vec\u001b[0;34m(sentence_word, asize, bsize, w2v_model)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2v_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'generator' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "print(build_sentence_vec(sentence_word[1],36,300,w2v_model))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
